{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Chains Demo\n",
    "Document Chains allow you to process and analyze large amounts of text data efficiently. They provide a structured approach to working with documents, enabling you to retrieve, filter, refine, and rank them based on specific criteria.\n",
    "\n",
    "By using different types of Document Chains like **Stuff, Refine, Map Reduce, or Map Re-rank**, you can perform specific operations on the retrieved documents and obtain more accurate and relevant results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import textwrap\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "# We will cover docstores and splitters in more details when we get to retrieval\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GoogleGenerativeAI(\n",
    "  model=\"gemini-1.5-pro-latest\",\n",
    "  temperature=0.5,\n",
    "  google_api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stuff Chain\n",
    "This involves putting all relevant data into the Prompt for LangChain's StuffDocumentsChain to process. The advantage of this method is that it only requires one call to the LLM, and the model has access to all the information at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"../pdf/CV (1).pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for doc in docs:\n",
    "  cnt = cnt + 1\n",
    "  print(\"---- Document #\", cnt)\n",
    "  print(doc.page_content.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template =\"\"\"\n",
    "You are given a Resume as the below text. \n",
    "-----\n",
    "{text}\n",
    "-----\n",
    "Question: Please respond with the Key Skills and Experience summary of the person. \n",
    "Key Skills:\n",
    "Experience Summary: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "stuff_chain = load_summarize_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
    "print(stuff_chain.llm_chain.prompt.template)\n",
    "\n",
    "output_summary = stuff_chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refine Chain\n",
    "\n",
    "The Refine Documents Chain uses an iterative process to generate a response by analyzing each input document and updating its answer accordingly.\n",
    "\n",
    "It passes all non-documents inputs, the current document, and the latest intermediate answer to an LLM chain to obtain a new answer for each document.\n",
    "\n",
    "This chain is ideal for tasks that involve analyzing more document that can fit in the model's context, as it only passes a single document to the LLM at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_chain = load_summarize_chain(model, chain_type=\"refine\")\n",
    "print(refine_chain.refine_llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_summary = refine_chain.run(docs)\n",
    "output_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map-Reduce Chain\n",
    "\n",
    "To process large amounts of data efficiently, the MapReduceDocumentsChain method is used.\n",
    "\n",
    "This involves applying an LLM chain to each document individually (in the Map step), producing a new document. Then, all the new documents can be compressed before passing them to the combine documents chain.\n",
    "\n",
    "This compression step is performed recursively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_reduce_chain = load_summarize_chain(model, chain_type=\"map_reduce\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(map_reduce_chain.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just using the first 20 chunks as I don't want to run too long.\n",
    "output_summary = map_reduce_chain.run(docs)\n",
    "print(output_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
