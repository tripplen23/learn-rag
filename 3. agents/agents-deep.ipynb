{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting a bit more deeper into Agents\n",
    "\n",
    "### Conversational ReAct Agents\n",
    "\n",
    "This agent is designed for use in conversational settings. It incorporate the React framework to determine which tool to use and utilizes memory to remember previous conversation interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_react_agent, load_tools\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import initialize_agent\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GoogleGenerativeAI(\n",
    "  model=\"gemini-1.5-pro-latest\", \n",
    "  google_api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "conversational_agent = initialize_agent(\n",
    "    agent=\"conversational-react-description\", \n",
    "    tools=tools, \n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    memory=memory,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_1 = conversational_agent.run(\"Add 7 to 9 and tell me the result\")\n",
    "output_2 = conversational_agent.run(\"Add 5 to the previous result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_1)\n",
    "print(output_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReAct Docstore\n",
    "\n",
    "This agent utilizes the React framewor to communicate with a docstore. It requires the availability of a Search tool and a Lookup tool with identical names. The Search tools is used to search for a document, while the Lookup tool looks up a term within the most recently found document.\n",
    "\n",
    "A **docstore** in LangChain is essentially a storage system for documents. It provides a way for LangChain agents to access and interact with information. Think of it like a library, but instead of books, it holds pieces of text and associated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain import Wikipedia\n",
    "from langchain.agents.react.base import DocstoreExplorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "docstore = DocstoreExplorer(Wikipedia())\n",
    "tools=[\n",
    "  Tool(name=\"Search\", func=docstore.search, description=\"useful for when you need to search wikipedia\"),\n",
    "  Tool(name=\"Lookup\", func=docstore.lookup, description=\"useful for when you need to lookup a term in wikipedia\")\n",
    "]\n",
    "\n",
    "docstore_agent=initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=\"react-docstore\",\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docstore_agent(\"Tell me a few key things about Ho Chi Minh.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-ask with Search\n",
    "This agent utilizes the intermediate Answer tool for self-asking questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "tools = [\n",
    "  Tool(\n",
    "    func=search.run,\n",
    "    name=\"Intermediate Answer\",\n",
    "    description=\"Useful for when you need to search the Internet for information\"\n",
    "  )\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "  tools=tools,\n",
    "  llm=llm,\n",
    "  agent=\"self-ask-with-search\",\n",
    "  verbose=True,\n",
    "  handle_parsing_errors=True,\n",
    "  max_interations=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Add a delay to avoid hitting the rate limit\n",
    "time.sleep(2)\n",
    "print(agent.invoke(\"Question: Who was the president of USA when the first Moon landing took place?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
